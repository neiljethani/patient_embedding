{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/work/pip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_input, d_model, seq_len, deepN = None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode = nn.Linear(d_input*seq_len, d_model)\n",
    "        if deepN is not None:\n",
    "            self.linears = nn.ModuleList([nn.Linear(d_model*seq_len, d_model*seq_len) for _ in range(deepN)])\n",
    "            self.deep = True\n",
    "        else:\n",
    "            self.deep = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.encode(x))\n",
    "        if self.deep:\n",
    "            for layer in self.linears:\n",
    "                x = F.relu(layer(x))\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_input, d_model, seq_len, deepN = None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode = nn.Linear(d_model, d_input*seq_len)\n",
    "        if deepN is not None:\n",
    "            self.linears = nn.ModuleList([nn.Linear(d_model*seq_len, d_model*seq_len) for _ in range(deepN)])\n",
    "            self.deep = True\n",
    "        else:\n",
    "            self.deep = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.deep:\n",
    "            for layer in self.linears:\n",
    "                x = F.relu(layer(x))\n",
    "        x = F.relu(self.decode(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, noise = None):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.noise = noise\n",
    "    \n",
    "    def forward(self, src):\n",
    "        return self.decode(self.encode(src))\n",
    "    \n",
    "    def encode(self, src):\n",
    "        if self.noise is not None:\n",
    "            return self.encoder(self.noise(src))\n",
    "        else:\n",
    "            return self.encoder(src)\n",
    "    \n",
    "    def decode(self, memory):\n",
    "        return self.decoder(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(d_input, N = None, max_len = 24, dropout=0.15):\n",
    "    #Define Dimensions\n",
    "    d_model = int(d_input*max_len/4)\n",
    "    \n",
    "    Noise = nn.Dropout(dropout) if dropout is not None else None\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(d_input, d_model, max_len, N),\n",
    "        Decoder(d_input, d_model, max_len, N),\n",
    "        Noise\n",
    "    )\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCompute:\n",
    "    def __init__(self, criterion, opt = None):\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt \n",
    "        \n",
    "    def __call__(self, x, y, norm = None, train = True):\n",
    "        loss = 0\n",
    "        if norm is not None:\n",
    "            for i, j , n in zip(x, y, norm):\n",
    "                loss += self.criterion(i.contiguous(), j.contiguous())/n\n",
    "        else:\n",
    "            for i, j in zip(x, y):\n",
    "                loss += self.criterion(i.contiguous(), j.contiguous())\n",
    "\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            if self.opt is not None:\n",
    "                self.opt.step()\n",
    "                self.opt.optimizer.zero_grad()\n",
    "                \n",
    "        return loss.item()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(batch, d_input, seq_len, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.uniform(-1, 1, size=(batch, 1, d_input*seq_len)))\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch():\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = src\n",
    "        self.tgt = tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.0474853515625\n"
     ]
    }
   ],
   "source": [
    "d_input = 17\n",
    "seq_len = 24\n",
    "batches = 512\n",
    "loss_fn = LossCompute(nn.MSELoss())\n",
    "\n",
    "model = make_model(d_input = d_input, max_len = seq_len).float()\n",
    "\n",
    "for i, batch in enumerate(data_gen(batches, d_input, seq_len, 1)):\n",
    "    tgt_pred = model.forward(batch.src.float())\n",
    "    loss = loss_fn(tgt_pred, batch.tgt.float())\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
